{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from pandas import Series\n",
      "from pandas import DataFrame as DF\n",
      "from scipy.sparse import csr_matrix\n",
      "from scipy.sparse import hstack\n",
      "from scipy.sparse import vstack\n",
      "import utils\n",
      "\n",
      "import logging\n",
      "import sys\n",
      "from time import time\n",
      "\n",
      "import numpy as np\n",
      "import sklearn\n",
      "import scipy\n",
      "import pylab as pl\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "from sklearn.utils.extmath import density\n",
      "from sklearn import metrics\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "# Display progress logs on stdout\n",
      "logging.basicConfig(level=logging.INFO,\n",
      "                    format='%(asctime)s %(levelname)s %(message)s')\n",
      "\n",
      "def trim(s):\n",
      "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
      "    \"\"\"Balls to that, actually\"\"\"\n",
      "    # return s if len(s) <= 80 else s[:77] + \"...\"\n",
      "    return s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Vendor:  Continuum Analytics, Inc.\n",
        "Package: iopro\n",
        "Message: trial mode expires in 29 days\n",
        "Vendor:  Continuum Analytics, Inc.\n",
        "Package: iopro\n",
        "Message: trial mode expires in 29 days\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# constants\n",
      "select_chi2=10000\n",
      "print_top10=True\n",
      "print_report=True\n",
      "print_cm=False\n",
      "save_fig=True\n",
      "\n",
      "categories = [\"1\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data\n",
      "feature_names = np.array(pd.read_pickle(\"feature_names.pickle\"))\n",
      "X_train_comps = utils.load_csr(\"data/X_train_comps\")\n",
      "X_train_tfidf = utils.load_coo(\"data/X_train_tfidf\")\n",
      "X_test_comps = utils.load_csr(\"data/X_test_comps\")\n",
      "X_test_tfidf = utils.load_coo(\"data/X_test_tfidf\")\n",
      "\n",
      "y_train = utils.load_array(\"data/y_train\")\n",
      "y_test = utils.load_array(\"data/y_test\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class L1LinearSVC(LinearSVC):\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        # The smaller C, the stronger the regularization.\n",
      "        # The more regularization, the more sparsity.\n",
      "        self.transformer_ = LinearSVC(penalty=\"l1\",\n",
      "                                      dual=False, tol=1e-3)\n",
      "        X = self.transformer_.fit_transform(X, y)\n",
      "        return LinearSVC.fit(self, X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        X = self.transformer_.transform(X)\n",
      "        return LinearSVC.predict(self, X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Benchmark method\n",
      "def benchmark(clf):\n",
      "    print('_' * 80)\n",
      "    print(\"Training: \")\n",
      "    print(clf)\n",
      "    t0 = time()\n",
      "    clf.fit(X_train, y_train)\n",
      "    train_time = time() - t0\n",
      "    print(\"train time: %0.3fs\" % train_time)\n",
      "\n",
      "    t0 = time()\n",
      "    pred = clf.predict(X_test)\n",
      "    test_time = time() - t0\n",
      "    print(\"test time:  %0.3fs\" % test_time)\n",
      "\n",
      "    score = metrics.f1_score(y_test, pred)\n",
      "    print(\"f1-score:   %0.3f\" % score)\n",
      "\n",
      "    if hasattr(clf, 'coef_'):\n",
      "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
      "        print(\"density: %f\" % density(clf.coef_))\n",
      "\n",
      "        if print_top10 and feature_names is not None:\n",
      "            print(\"top 10 keywords per class:\")\n",
      "            for i, category in enumerate(categories):\n",
      "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
      "                print(trim(\"%s: %s\"\n",
      "                      % (category, \" \".join(feature_names[top10]))))\n",
      "        print()\n",
      "\n",
      "    if print_report:\n",
      "        print(\"classification report:\")\n",
      "        print(metrics.classification_report(y_test, pred))\n",
      "                                            # target_names=categories))\n",
      "\n",
      "    if print_cm:\n",
      "        print(\"confusion matrix:\")\n",
      "        print(metrics.confusion_matrix(y_test, pred))\n",
      "\n",
      "    print()\n",
      "    clf_descr = str(clf).split('(')[0]\n",
      "    return clf_descr, score, train_time, test_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Finally, get to work"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if select_chi2:\n",
      "    print(\"Extracting %d best features by a chi-squared test\" %\n",
      "          select_chi2)\n",
      "    t0 = time()\n",
      "    ch2 = SelectKBest(chi2, k=select_chi2)\n",
      "    X_train = hstack([X_train_comps, ch2.fit_transform(X_train_tfidf, y_train)])\n",
      "    X_test = hstack([X_test_comps, ch2.transform(X_test_tfidf)])\n",
      "    print(\"done in %fs\" % (time() - t0))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extracting 10000 best features by a chi-squared test\n",
        "done in 1.031375s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "()\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gotta hold results somewhere\n",
      "results = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for clf, name in (\n",
      "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
      "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
      "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
      "        (KNeighborsClassifier(n_neighbors=10), \"kNN\")):\n",
      "    print('=' * 80)\n",
      "    print(name)\n",
      "    results.append(benchmark(clf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "================================================================================\n",
        "Ridge Classifier\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
        "        max_iter=None, normalize=False, solver=lsqr, tol=0.01)\n",
        "train time: 0.323s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.192s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.852\n",
        "dimensionality: 10008\n",
        "density: 1.000000\n",
        "top 10 keywords per class:\n",
        "1: 2))  4 of  17% 7.1 al sp a lar 5-y all. adeno aff_sim\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.93      0.97      0.95       733\n",
        "       True       0.92      0.79      0.85       268\n",
        "\n",
        "avg / total       0.93      0.93      0.92      1001\n",
        "\n",
        "()\n",
        "================================================================================\n",
        "Perceptron\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
        "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=False,\n",
        "      verbose=0, warm_start=False)\n",
        "train time: 0.846s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.194s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.863\n",
        "dimensionality: 10008\n",
        "density: 0.867506\n",
        "top 10 keywords per class:\n",
        "1: 99m al sp 2 mo aa.  a mas alan  999 23,  : (1) ada\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.95      0.95      0.95       733\n",
        "       True       0.87      0.86      0.86       268\n",
        "\n",
        "avg / total       0.93      0.93      0.93      1001\n",
        "\n",
        "()\n",
        "================================================================================\n",
        "Passive-Aggressive\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "PassiveAggressiveClassifier(C=1.0, fit_intercept=True, loss=hinge, n_iter=50,\n",
        "              n_jobs=1, random_state=None, shuffle=False, verbose=0,\n",
        "              warm_start=False)\n",
        "train time: 1.076s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.193s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.875\n",
        "dimensionality: 10008\n",
        "density: 0.905576\n",
        "top 10 keywords per class:\n",
        "1: 25 m 4 of  2 mo : ( : (1) a tu al sp 99m alan  ada\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.95      0.97      0.96       733\n",
        "       True       0.90      0.85      0.87       268\n",
        "\n",
        "avg / total       0.93      0.94      0.93      1001\n",
        "\n",
        "()\n",
        "================================================================================\n",
        "kNN\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "KNeighborsClassifier(algorithm=auto, leaf_size=30, metric=minkowski,\n",
        "           n_neighbors=10, p=2, weights=uniform)\n",
        "train time: 0.575s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  4.807s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.882\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.94      0.98      0.96       733\n",
        "       True       0.95      0.82      0.88       268\n",
        "\n",
        "avg / total       0.94      0.94      0.94      1001\n",
        "\n",
        "()\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for penalty in [\"l2\", \"l1\"]:\n",
      "    print('=' * 80)\n",
      "    print(\"%s penalty\" % penalty.upper())\n",
      "    # Train Liblinear model\n",
      "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
      "                                            dual=False, tol=1e-3)))\n",
      "\n",
      "    # Train SGD model\n",
      "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                           penalty=penalty)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "================================================================================\n",
        "L2 penalty\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l2,\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "train time: 1.209s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.192s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.882\n",
        "dimensionality: 10008\n",
        "density: 1.000000\n",
        "top 10 keywords per class:\n",
        "1: 25 m aa.  a mas alan  : (1) 23,  al sp a tu 99m ada\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.95      0.97      0.96       733\n",
        "       True       0.92      0.85      0.88       268\n",
        "\n",
        "avg / total       0.94      0.94      0.94      1001\n",
        "\n",
        "()\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=l2, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 0.856s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.192s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.873\n",
        "dimensionality: 10008\n",
        "density: 0.876199\n",
        "top 10 keywords per class:\n",
        "1: a lar 23,  2 to  a sm : (1) a tu 2 mo ada al sp 99m\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.95      0.97      0.96       733\n",
        "       True       0.90      0.85      0.87       268\n",
        "\n",
        "avg / total       0.93      0.93      0.93      1001\n",
        "\n",
        "()\n",
        "================================================================================\n",
        "L1 penalty\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l1,\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "train time: 0.898s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.193s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.894\n",
        "dimensionality: 10008\n",
        "density: 0.028677\n",
        "top 10 keywords per class:\n",
        "1: ada 30- 6%.  alan  a sev 4 s aller a tu a sol 2 d\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.95      0.98      0.96       733\n",
        "       True       0.94      0.85      0.89       268\n",
        "\n",
        "avg / total       0.95      0.95      0.95      1001\n",
        "\n",
        "()\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=l1, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 1.561s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.192s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.896\n",
        "dimensionality: 10008\n",
        "density: 0.047662\n",
        "top 10 keywords per class:\n",
        "1: 23,  ain i 8.9 4 of  a sev 99m 2 mo a tu al sp ada\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.96      0.97      0.96       733\n",
        "       True       0.91      0.88      0.90       268\n",
        "\n",
        "avg / total       0.94      0.95      0.94      1001\n",
        "\n",
        "()\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train SGD with Elastic Net penalty\n",
      "print('=' * 80)\n",
      "print(\"Elastic-Net penalty\")\n",
      "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                       penalty=\"elasticnet\")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "================================================================================\n",
        "Elastic-Net penalty\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=elasticnet, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 1.643s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.192s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.879\n",
        "dimensionality: 10008\n",
        "density: 0.064149\n",
        "top 10 keywords per class:\n",
        "1: : (1) ain i 23,  a sev 4 of  99m al sp a tu 2 mo ada\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.95      0.97      0.96       733\n",
        "       True       0.91      0.85      0.88       268\n",
        "\n",
        "avg / total       0.94      0.94      0.94      1001\n",
        "\n",
        "()\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train NearestCentroid without threshold\n",
      "print('=' * 80)\n",
      "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
      "results.append(benchmark(NearestCentroid()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "================================================================================\n",
        "NearestCentroid (aka Rocchio classifier)\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "NearestCentroid(metric=euclidean, shrink_threshold=None)\n",
        "train time: 0.675s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.208s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.882\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.94      0.98      0.96       733\n",
        "       True       0.93      0.84      0.88       268\n",
        "\n",
        "avg / total       0.94      0.94      0.94      1001\n",
        "\n",
        "()\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Input X must be non-negative\n",
      "# # Train sparse Naive Bayes classifiers\n",
      "# print('=' * 80)\n",
      "# print(\"Naive Bayes\")\n",
      "# results.append(benchmark(MultinomialNB(alpha=.01)))\n",
      "# results.append(benchmark(BernoulliNB(alpha=.01)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('=' * 80)\n",
      "print(\"LinearSVC with L1-based feature selection\")\n",
      "results.append(benchmark(L1LinearSVC()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "================================================================================\n",
        "LinearSVC with L1-based feature selection\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "L1LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "      intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l2,\n",
        "      random_state=None, tol=0.0001, verbose=0)\n",
        "train time: 1.141s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.031s\n",
        "f1-score:   0.895\n",
        "dimensionality: 285\n",
        "density: 1.000000\n",
        "top 10 keywords per class:\n",
        "1:  (mu  (g  (42  (ps  (on  (fo  (m  (ci)  (19  (gv\n",
        "()\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.95      0.98      0.96       733\n",
        "       True       0.94      0.85      0.89       268\n",
        "\n",
        "avg / total       0.95      0.95      0.95      1001\n",
        "\n",
        "()\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make some plots\n",
      "\n",
      "indices = np.arange(len(results))\n",
      "\n",
      "results = [[x[i] for x in results] for i in range(4)]\n",
      "\n",
      "clf_names, score, training_time, test_time = results\n",
      "training_time = np.array(training_time) / np.max(training_time)\n",
      "test_time = np.array(test_time) / np.max(test_time)\n",
      "\n",
      "pl.figure(figsize=(12,8))\n",
      "pl.title(\"Score for %d best features\" % select_chi2)\n",
      "pl.barh(indices, score, .2, label=\"score\", color='r')\n",
      "pl.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
      "pl.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
      "pl.yticks(())\n",
      "pl.legend(loc='best')\n",
      "pl.subplots_adjust(left=.25)\n",
      "pl.subplots_adjust(top=.95)\n",
      "pl.subplots_adjust(bottom=.05)\n",
      "\n",
      "for i, c in zip(indices, clf_names):\n",
      "    pl.text(-.3, i, c)\n",
      "if save_fig:\n",
      "    pl.savefig(\"figures/benchmark_%d_feat\" % select_chi2)\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}