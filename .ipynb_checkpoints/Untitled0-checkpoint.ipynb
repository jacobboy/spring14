{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utils\n",
      "\n",
      "import logging\n",
      "from optparse import OptionParser\n",
      "import sys\n",
      "from time import time\n",
      "\n",
      "import numpy as np\n",
      "import sklearn\n",
      "import scipy\n",
      "import pylab as pl\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "from sklearn.utils.extmath import density\n",
      "from sklearn import metrics\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.svm import SVC\n",
      "from scipy.sparse import hstack"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = Series.from_pickle(\"feature_names.pickle\")\n",
      "X_train = utils.load_coo(\"X_train\")\n",
      "y_train = utils.load_array(\"y_train\")\n",
      "X_test = utils.load_coo(\"X_test\")\n",
      "y_test = utils.load_array(\"y_test\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://scikit-learn.org/dev/auto_examples/document_classification_20newsgroups.html#example-document-classification-20newsgroups-py\n",
      "# from __future__ import print_function\n",
      "categories = [\"1\"]\n",
      "\n",
      "select_chi2 = 200\n",
      "print(\"Extracting %d best features by a chi-squared test\" % select_chi2)\n",
      "t0 = time()\n",
      "ch2 = SelectKBest(chi2, k=select_chi2)\n",
      "X_train_ch2 = hstack([X_train_comps, ch2.fit_transform(X_train_tfidf, y_train_df)])\n",
      "X_test_ch2 = hstack([X_test_comps, ch2.transform(X_test_tfidf)])\n",
      "print(\"done in %fs\" % (time() - t0))\n",
      "print()\n",
      "\n",
      "# Display progress logs on stdout\n",
      "logging.basicConfig(level=logging.INFO,\n",
      "                    format='%(asctime)s %(levelname)s %(message)s')\n",
      "\n",
      "###############################################################################\n",
      "# Benchmark classifiers\n",
      "def benchmark(clf):\n",
      "    print('_' * 80)\n",
      "    print(\"Training: \")\n",
      "    print(clf)\n",
      "    t0 = time()\n",
      "    clf.fit(X_train_ch2, y_train_df)\n",
      "    train_time = time() - t0\n",
      "    print(\"train time: %0.3fs\" % train_time)\n",
      "\n",
      "    t0 = time()\n",
      "    pred = clf.predict(X_test_ch2)\n",
      "    test_time = time() - t0\n",
      "    print(\"test time:  %0.3fs\" % test_time)\n",
      "\n",
      "    score = metrics.f1_score(y_test_df, pred)\n",
      "    print(\"f1-score:   %0.3f\" % score)\n",
      "\n",
      "    if hasattr(clf, 'coef_'):\n",
      "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
      "        print(\"density: %f\" % density(clf.coef_))\n",
      "\n",
      "        # if opts.print_top10 and feature_names is not None:\n",
      "        print(\"top 50 keywords per class:\")\n",
      "        for i, category in enumerate(categories):\n",
      "            top10 = np.argsort(clf.coef_[i])[-50:]\n",
      "            print(\"%s: %s\" % (category, \";\".join(feature_names[top10])))\n",
      "        print()\n",
      "\n",
      "    # if opts.print_report:\n",
      "    if True:\n",
      "        print(\"classification report:\")\n",
      "        print(metrics.classification_report([x for x in y_test_df], pred))\n",
      "                                            # target_names=categories))\n",
      "\n",
      "    # if opts.print_cm:\n",
      "    if True:\n",
      "        print(\"confusion matrix:\")\n",
      "        print(metrics.confusion_matrix(y_test_df, pred))\n",
      "\n",
      "    print()\n",
      "    clf_descr = str(clf).split('(')[0]\n",
      "    return clf_descr, score, train_time, test_time\n",
      "\n",
      "results = []\n",
      "# for clf, name in (\n",
      "#         (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
      "#         (Perceptron(n_iter=50), \"Perceptron\"),\n",
      "#         (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
      "#         (KNeighborsClassifier(n_neighbors=10), \"kNN\")):\n",
      "#     print('=' * 80)\n",
      "#     print(name)\n",
      "#     results.append(benchmark(clf))\n",
      "\n",
      "for penalty in [\"l2\", \"l1\"]:\n",
      "    print('=' * 80)\n",
      "    print(\"%s penalty\" % penalty.upper())\n",
      "    # Train Liblinear model\n",
      "    results.append(benchmark(LinearSVC(loss='l2',\n",
      "                                       penalty=penalty,\n",
      "                                       dual=False,\n",
      "                                       tol=1e-3)))\n",
      "\n",
      "    # Train SGD model\n",
      "    results.append(benchmark(SGDClassifier(alpha=.0001,\n",
      "                                           n_iter=50,\n",
      "                                           penalty=penalty)))\n",
      "# # Train SGD with Elastic Net penalty\n",
      "# print('=' * 80)\n",
      "# print(\"Elastic-Net penalty\")\n",
      "# results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "#                                        penalty=\"elasticnet\")))\n",
      "\n",
      "# # Train NearestCentroid without threshold\n",
      "# print('=' * 80)\n",
      "# print(\"NearestCentroid (aka Rocchio classifier)\")\n",
      "# results.append(benchmark(NearestCentroid()))\n",
      "\n",
      "# # Train sparse Naive Bayes classifiers\n",
      "# print('=' * 80)\n",
      "# print(\"Naive Bayes\")\n",
      "# results.append(benchmark(MultinomialNB(alpha=.01)))\n",
      "# results.append(benchmark(BernoulliNB(alpha=.01)))\n",
      "\n",
      "class L1LinearSVC(LinearSVC):\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        # The smaller C, the stronger the regularization.\n",
      "        # The more regularization, the more sparsity.\n",
      "        self.transformer_ = LinearSVC(penalty=\"l1\",\n",
      "                                      dual=False, tol=1e-3)\n",
      "        X = self.transformer_.fit_transform(X, y)\n",
      "        return LinearSVC.fit(self, X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        X = self.transformer_.transform(X)\n",
      "        return LinearSVC.predict(self, X)\n",
      "\n",
      "print('=' * 80)\n",
      "print(\"LinearSVC with L1-based feature selection\")\n",
      "results.append(benchmark(L1LinearSVC()))\n",
      "\n",
      "# make some plots\n",
      "\n",
      "indices = np.arange(len(results))\n",
      "\n",
      "results = [[x[i] for x in results] for i in range(4)]\n",
      "\n",
      "clf_names, score, training_time, test_time = results\n",
      "training_time = np.array(training_time) / np.max(training_time)\n",
      "test_time = np.array(test_time) / np.max(test_time)\n",
      "\n",
      "pl.figure(figsize=(12,8))\n",
      "pl.title(\"Score\")\n",
      "pl.barh(indices, score, .2, label=\"score\", color='r')\n",
      "pl.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
      "pl.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
      "pl.yticks(())\n",
      "pl.legend(loc='best')\n",
      "pl.subplots_adjust(left=.25)\n",
      "pl.subplots_adjust(top=.95)\n",
      "pl.subplots_adjust(bottom=.05)\n",
      "\n",
      "for i, c in zip(indices, clf_names):\n",
      "    pl.text(-.3, i, c)\n",
      "\n",
      "pl.savefig(\"fig\" + str(fignum))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://scikit-learn.org/stable/auto_examples/grid_search_digits.html#example-grid-search-digits-py\n",
      "# Set the parameters by cross-validation\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
      "                     'C': [1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "\n",
      "scores = ['precision', 'recall']\n",
      "\n",
      "for score in scores:\n",
      "    t0 = time()\n",
      "\n",
      "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "    print()\n",
      "\n",
      "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, scoring=score)\n",
      "    clf.fit(X_train, y_train_df)\n",
      "\n",
      "    print(\"Best parameters set found on development set:\")\n",
      "    print()\n",
      "    print(clf.best_estimator_)\n",
      "    print()\n",
      "    print(\"Grid scores on development set:\")\n",
      "    print()\n",
      "    for params, mean_score, scores in clf.grid_scores_:\n",
      "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() / 2, params))\n",
      "    print()\n",
      "\n",
      "    print(\"Detailed classification report:\")\n",
      "    print()\n",
      "    print(\"The model is trained on the full development set.\")\n",
      "    print(\"The scores are computed on the full evaluation set.\")\n",
      "    print()\n",
      "    y_true, y_pred = y_test, clf.predict(X_test)\n",
      "    print(classification_report(y_true, y_pred))\n",
      "    print(\"done in %fs\" % (time() - t0))\n",
      "    print()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}